{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 10000\n",
    "n_test = 5000\n",
    "\n",
    "width = 100\n",
    "height = 100\n",
    "\n",
    "n_refs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n_samples, n_refs, width = 100, height = 100):\n",
    "    target_x = np.random.randint(0, width, size=(n_samples, 1))\n",
    "    target_y = np.random.randint(0, height, size=(n_samples, 1))\n",
    "    \n",
    "    reference_x = np.random.randint(0, width,  size=(n_samples, n_refs))\n",
    "    reference_y = np.random.randint(0, height, size=(n_samples, n_refs))\n",
    "    \n",
    "    distances = np.zeros(shape=(n_samples, n_refs))\n",
    "    \n",
    "    for ip in range(n_refs):\n",
    "        distances[:, ip:ip+1] = np.sqrt(np.square(reference_x[:, ip:ip+1] - target_x) + np.square(reference_y[:, ip:ip+1] - target_y))\n",
    "        \n",
    "    target_x_cols = [ \"target_x\" ]\n",
    "    target_y_cols = [ \"target_y\" ]\n",
    "    reference_x_cols = [ \"ref_x_{}\".format(i+1) for i in range(n_refs) ]\n",
    "    reference_y_cols = [ \"ref_y_{}\".format(i+1) for i in range(n_refs) ]\n",
    "    distances_cols = [ \"distance_{}\".format(i+1) for i in range(n_refs) ]\n",
    "    \n",
    "    target_x_df = pd.DataFrame(target_x, columns=target_x_cols)\n",
    "    target_y_df = pd.DataFrame(target_y, columns=target_y_cols)\n",
    "    reference_x_df = pd.DataFrame(reference_x, columns=reference_x_cols)\n",
    "    reference_y_df = pd.DataFrame(reference_y, columns=reference_y_cols)\n",
    "    distances_df = pd.DataFrame(distances, columns=distances_cols)\n",
    "    \n",
    "    data = pd.concat([target_x_df, target_y_df, reference_x_df, reference_y_df, distances_df], axis=1)\n",
    "\n",
    "    target_cols = [ \"target_x\", \"target_y\" ]\n",
    "    reference_cols = []\n",
    "    for x_col, y_col in zip(reference_x_cols, reference_y_cols):\n",
    "        reference_cols += [x_col, y_col]\n",
    "    cols = target_cols + reference_cols + distances_cols\n",
    "\n",
    "    data = data[cols]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_data(n_samples=n_train, n_refs=n_refs, width=width, height=height)\n",
    "test_data = create_data(n_samples=n_train, n_refs=n_refs, width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data_df, cols, mu=0, sigma=1, min_noise=0, max_noise=5, n_b=1, p_b=0.1, R_NLoS=5):\n",
    "    \n",
    "    n_samples = len(data_df)\n",
    "    df_list = [data_df]\n",
    "    for item in data_df[cols]:\n",
    "        distance = data_df[[item]].to_numpy()\n",
    "        \n",
    "        # 정규 분포를 따르는 노이즈\n",
    "        noise_with_std = sigma * np.random.randn(n_samples, 1) + mu\n",
    "        # print(min(noise_with_std), max(noise_with_std))\n",
    "\n",
    "        # 균등 분포를 따르는 노이즈\n",
    "        noise_with_uniform = np.random.rand(n_samples, 1) * max_noise\n",
    "        noise_with_uniform[noise_with_uniform < min_noise] = min_noise\n",
    "        # print(min(noise_with_uniform), max(noise_with_uniform))\n",
    "\n",
    "        # 베르누이 분포를 따르는 노이즈\n",
    "        noise_with_binomial = R_NLoS * np.random.binomial(n=n_b, p=p_b, size=(n_samples, 1))\n",
    "        # print(min(noise_with_binomial), max(noise_with_binomial))\n",
    "\n",
    "        total_noise = noise_with_std + noise_with_uniform + noise_with_binomial\n",
    "        \n",
    "        distance_with_noise = distance + total_noise\n",
    "                \n",
    "        distance_with_noise[distance_with_noise < 0] = 0\n",
    "        \n",
    "        df_list.append( pd.DataFrame(distance_with_noise, columns=[item + \"_with_noise\"]) )\n",
    "        \n",
    "    return pd.concat(df_list, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_cols = [ \"distance_{}\".format(i+1) for i in range(n_refs) ]\n",
    "\n",
    "train_data = add_noise(train_data, distances_cols)\n",
    "test_data = add_noise(test_data, distances_cols)\n",
    "\n",
    "train_data.to_csv(\"train.csv\", index=False)\n",
    "test_data.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
